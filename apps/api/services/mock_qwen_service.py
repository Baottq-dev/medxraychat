"""
MedXrayChat Backend - Mock Qwen-VL Service for Testing

This mock service simulates Qwen-VL responses without loading the actual model.
Use this when you don't have the Qwen model weights or GPU resources.
"""
import time
import random
from typing import List, Optional, Tuple
from PIL import Image
from loguru import logger

from schemas import Detection, BoundingBox


# Vietnamese response templates based on YOLO detections
ANALYSIS_TEMPLATES = {
    "normal": """**Káº¿t quáº£ phÃ¢n tÃ­ch áº£nh X-quang ngá»±c:**

ğŸ“‹ **Nháº­n xÃ©t tá»•ng quan:**
HÃ¬nh áº£nh X-quang ngá»±c tháº³ng cháº¥t lÆ°á»£ng tá»‘t, Ä‘á»§ Ä‘á»ƒ Ä‘Ã¡nh giÃ¡.

ğŸ« **Phá»•i:**
- Hai pháº¿ trÆ°á»ng sÃ¡ng, khÃ´ng tháº¥y tá»•n thÆ°Æ¡ng thÃ¢m nhiá»…m rÃµ
- KhÃ´ng cÃ³ hÃ¬nh áº£nh Ä‘Ã´ng Ä‘áº·c hoáº·c xáº¹p phá»•i
- GÃ³c sÆ°á»n hoÃ nh hai bÃªn tá»± do

â¤ï¸ **Tim vÃ  trung tháº¥t:**
- BÃ³ng tim kÃ­ch thÆ°á»›c bÃ¬nh thÆ°á»ng (CTR < 50%)
- Trung tháº¥t khÃ´ng giÃ£n, khÃ´ng lá»‡ch

ğŸ¦´ **XÆ°Æ¡ng:**
- CÃ¡c xÆ°Æ¡ng sÆ°á»n, xÆ°Æ¡ng Ä‘Ã²n khÃ´ng tháº¥y báº¥t thÆ°á»ng rÃµ

âœ… **Káº¿t luáº­n:** HÃ¬nh áº£nh X-quang ngá»±c trong giá»›i háº¡n bÃ¬nh thÆ°á»ng.

âš ï¸ *ÄÃ¢y lÃ  káº¿t quáº£ phÃ¢n tÃ­ch AI há»— trá»£. Quyáº¿t Ä‘á»‹nh cuá»‘i cÃ¹ng thuá»™c vá» bÃ¡c sÄ©.*
""",
    
    "with_findings": """**Káº¿t quáº£ phÃ¢n tÃ­ch áº£nh X-quang ngá»±c:**

ğŸ“‹ **Nháº­n xÃ©t tá»•ng quan:**
HÃ¬nh áº£nh X-quang ngá»±c tháº³ng. PhÃ¡t hiá»‡n má»™t sá»‘ báº¥t thÆ°á»ng cáº§n lÆ°u Ã½.

ğŸ” **CÃ¡c phÃ¡t hiá»‡n báº¥t thÆ°á»ng:**
{findings}

ğŸ“Š **Chi tiáº¿t vá»‹ trÃ­:**
{locations}

ğŸ’¡ **Äá» xuáº¥t:**
- Cáº§n Ä‘á»‘i chiáº¿u vá»›i lÃ¢m sÃ ng vÃ  tiá»n sá»­ bá»‡nh nhÃ¢n
- CÃ³ thá»ƒ cáº§n thÃªm cÃ¡c thÄƒm dÃ² bá»• sung náº¿u cáº§n thiáº¿t

âš ï¸ *ÄÃ¢y lÃ  káº¿t quáº£ phÃ¢n tÃ­ch AI há»— trá»£. Quyáº¿t Ä‘á»‹nh cuá»‘i cÃ¹ng thuá»™c vá» bÃ¡c sÄ©.*
""",
}

# Vietnamese descriptions for each finding class
FINDING_DESCRIPTIONS = {
    "Aortic enlargement": "PhÃ¬nh Ä‘á»™ng máº¡ch chá»§ - cung Ä‘á»™ng máº¡ch chá»§ giÃ£n rá»™ng",
    "Atelectasis": "Xáº¹p phá»•i - giáº£m thá»ƒ tÃ­ch phá»•i khu trÃº",
    "Calcification": "VÃ´i hÃ³a - cÃ¡c ná»‘t vÃ´i hÃ³a trong nhu mÃ´ phá»•i",
    "Cardiomegaly": "Tim to - chá»‰ sá»‘ tim/ngá»±c (CTR) > 50%",
    "Clavicle fracture": "GÃ£y xÆ°Æ¡ng Ä‘Ã²n - Ä‘Æ°á»ng gÃ£y xÆ°Æ¡ng Ä‘Ã²n",
    "Consolidation": "ÄÃ´ng Ä‘áº·c phá»•i - vÃ¹ng má» Ä‘á»“ng nháº¥t do tá»•n thÆ°Æ¡ng nhu mÃ´",
    "Edema": "PhÃ¹ phá»•i - hÃ¬nh áº£nh má» lan tá»a hai bÃªn",
    "Emphysema": "KhÃ­ pháº¿ thÅ©ng - phá»•i cÄƒng giÃ£n, tÄƒng sÃ¡ng",
    "Enlarged PA": "Äá»™ng máº¡ch phá»•i giÃ£n - rá»‘n phá»•i to",
    "ILD": "Bá»‡nh phá»•i káº½ - tá»•n thÆ°Æ¡ng mÃ´ káº½ lan tá»a",
    "Infiltration": "ThÃ¢m nhiá»…m - vÃ¹ng má» khÃ´ng Ä‘á»“ng nháº¥t",
    "Lung Opacity": "Má» phá»•i - vÃ¹ng giáº£m sÃ¡ng trong nhu mÃ´ phá»•i",
    "Lung cavity": "Hang phá»•i - tá»•n thÆ°Æ¡ng dáº¡ng hang cÃ³ thÃ nh",
    "Lung cyst": "Nang phá»•i - tá»•n thÆ°Æ¡ng dáº¡ng nang thÃ nh má»ng",
    "Mediastinal shift": "Di lá»‡ch trung tháº¥t - trung tháº¥t lá»‡ch sang má»™t bÃªn",
    "Nodule/Mass": "Ná»‘t/Khá»‘i u - tá»•n thÆ°Æ¡ng dáº¡ng ná»‘t hoáº·c khá»‘i",
    "Pleural effusion": "TrÃ n dá»‹ch mÃ ng phá»•i - má» gÃ³c sÆ°á»n hoÃ nh",
    "Pleural thickening": "DÃ y mÃ ng phá»•i - dÃ y mÃ ng phá»•i thÃ nh",
    "Pneumothorax": "TrÃ n khÃ­ mÃ ng phá»•i - khÃ­ trong khoang mÃ ng phá»•i",
    "Pulmonary fibrosis": "XÆ¡ phá»•i - tá»•n thÆ°Æ¡ng xÆ¡ hÃ³a nhu mÃ´ phá»•i",
    "Rib fracture": "GÃ£y xÆ°Æ¡ng sÆ°á»n - Ä‘Æ°á»ng gÃ£y xÆ°Æ¡ng sÆ°á»n",
    "Other lesion": "Tá»•n thÆ°Æ¡ng khÃ¡c - báº¥t thÆ°á»ng cáº§n Ä‘Ã¡nh giÃ¡ thÃªm",
}

# Location mapping based on bbox position
def get_location_text(bbox: BoundingBox, image_width: int = 2048, image_height: int = 2048) -> str:
    """Determine anatomical location based on bbox position."""
    x_center = (bbox.x1 + bbox.x2) / 2
    y_center = (bbox.y1 + bbox.y2) / 2
    
    # Horizontal position
    if x_center < image_width * 0.4:
        h_pos = "phá»•i pháº£i"
    elif x_center > image_width * 0.6:
        h_pos = "phá»•i trÃ¡i"
    else:
        h_pos = "vÃ¹ng trung tÃ¢m/trung tháº¥t"
    
    # Vertical position
    if y_center < image_height * 0.35:
        v_pos = "thÃ¹y trÃªn"
    elif y_center > image_height * 0.65:
        v_pos = "thÃ¹y dÆ°á»›i"
    else:
        v_pos = "thÃ¹y giá»¯a"
    
    return f"{v_pos} {h_pos}"


class MockQwenVLService:
    """Mock service that simulates Qwen-VL responses based on YOLO detections."""

    def __init__(self, model_name: Optional[str] = None):
        """Initialize mock service."""
        self.model_name = model_name or "MockQwen-VL (Testing)"
        self.model = "mock"  # Indicate it's loaded (as mock)
        self.processor = "mock"
        logger.warning("ğŸ§ª Using MOCK Qwen-VL Service - responses are simulated for testing")
        logger.info("   To use real Qwen model, set MOCK_QWEN_SERVICE=False in .env")

    def analyze(
        self,
        image: Image.Image | str,
        question: Optional[str] = None,
        yolo_detections: Optional[List[Detection]] = None,
        max_new_tokens: int = 1024,
    ) -> Tuple[str, List[Detection], int]:
        """Generate mock analysis response based on YOLO detections.
        
        Args:
            image: PIL Image or path to image file
            question: Optional question from doctor
            yolo_detections: YOLO detections to base response on
            max_new_tokens: Ignored in mock
            
        Returns:
            Tuple of (analysis text, detected bboxes (empty for mock), processing time)
        """
        start_time = time.time()
        
        # Simulate processing delay (100-500ms)
        time.sleep(random.uniform(0.1, 0.5))
        
        # Generate response based on YOLO detections
        if not yolo_detections or len(yolo_detections) == 0:
            response = ANALYSIS_TEMPLATES["normal"]
        else:
            # Build findings list
            findings_list = []
            locations_list = []
            
            for i, det in enumerate(yolo_detections, 1):
                desc = FINDING_DESCRIPTIONS.get(det.class_name, det.class_name)
                location = get_location_text(det.bbox)
                conf_level = "cao" if det.confidence > 0.7 else "trung bÃ¬nh" if det.confidence > 0.4 else "tháº¥p"
                
                findings_list.append(f"  {i}. **{det.class_name}** ({desc}) - Ä‘á»™ tin cáº­y {conf_level} ({det.confidence:.0%})")
                locations_list.append(f"  - {det.class_name}: {location}")
            
            findings_text = "\n".join(findings_list)
            locations_text = "\n".join(locations_list)
            
            response = ANALYSIS_TEMPLATES["with_findings"].format(
                findings=findings_text,
                locations=locations_text,
            )
        
        # If there's a specific question, add a response to it
        if question:
            response += f"\n\n---\nğŸ“ **Tráº£ lá»i cÃ¢u há»i cá»§a bÃ¡c sÄ©:**\n> \"{question}\"\n\n"
            response += self._generate_question_response(question, yolo_detections)
        
        processing_time = int((time.time() - start_time) * 1000)
        
        # Mock doesn't return additional detections
        return response, [], processing_time
    
    def _generate_question_response(self, question: str, detections: Optional[List[Detection]]) -> str:
        """Generate a contextual response to the doctor's question."""
        question_lower = question.lower()
        
        if any(word in question_lower for word in ["báº¥t thÆ°á»ng", "phÃ¡t hiá»‡n", "tháº¥y gÃ¬"]):
            if detections and len(detections) > 0:
                findings = ", ".join(set(d.class_name for d in detections))
                return f"Dá»±a trÃªn phÃ¢n tÃ­ch, cÃ¡c báº¥t thÆ°á»ng Ä‘Æ°á»£c phÃ¡t hiá»‡n bao gá»“m: {findings}. Cáº§n Ä‘á»‘i chiáº¿u vá»›i lÃ¢m sÃ ng Ä‘á»ƒ xÃ¡c nháº­n."
            else:
                return "KhÃ´ng phÃ¡t hiá»‡n báº¥t thÆ°á»ng rÃµ rá»‡t trÃªn áº£nh X-quang nÃ y. Tuy nhiÃªn, cáº§n káº¿t há»£p vá»›i khÃ¡m lÃ¢m sÃ ng Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ toÃ n diá»‡n."
        
        elif any(word in question_lower for word in ["viÃªm phá»•i", "pneumonia"]):
            consolidation_found = any(d.class_name in ["Consolidation", "Infiltration", "Lung Opacity"] for d in (detections or []))
            if consolidation_found:
                return "CÃ³ hÃ¬nh áº£nh Ä‘Ã´ng Ä‘áº·c/thÃ¢m nhiá»…m gá»£i Ã½ tá»•n thÆ°Æ¡ng viÃªm. Cáº§n káº¿t há»£p vá»›i triá»‡u chá»©ng lÃ¢m sÃ ng (sá»‘t, ho, khÃ³ thá»Ÿ) vÃ  xÃ©t nghiá»‡m mÃ¡u Ä‘á»ƒ cháº©n Ä‘oÃ¡n viÃªm phá»•i."
            else:
                return "KhÃ´ng tháº¥y hÃ¬nh áº£nh Ä‘Ã´ng Ä‘áº·c phá»•i Ä‘iá»ƒn hÃ¬nh cá»§a viÃªm phá»•i trÃªn áº£nh nÃ y. Tuy nhiÃªn, viÃªm phá»•i giai Ä‘oáº¡n sá»›m cÃ³ thá»ƒ chÆ°a biá»ƒu hiá»‡n rÃµ trÃªn X-quang."
        
        elif any(word in question_lower for word in ["tim", "heart", "cardiomegaly"]):
            heart_issue = any(d.class_name in ["Cardiomegaly", "Enlarged PA", "Pulmonary edema"] for d in (detections or []))
            if heart_issue:
                return "PhÃ¡t hiá»‡n bÃ³ng tim to vÃ /hoáº·c dáº¥u hiá»‡u á»© huyáº¿t phá»•i. Äá» nghá»‹ siÃªu Ã¢m tim Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ chá»©c nÄƒng tim."
            else:
                return "BÃ³ng tim trong giá»›i háº¡n bÃ¬nh thÆ°á»ng, chá»‰ sá»‘ tim/ngá»±c (CTR) Æ°á»›c tÃ­nh < 50%."
        
        elif any(word in question_lower for word in ["u", "khá»‘i", "nodule", "mass"]):
            nodule_found = any(d.class_name in ["Nodule/Mass", "Lung Opacity"] for d in (detections or []))
            if nodule_found:
                return "PhÃ¡t hiá»‡n tá»•n thÆ°Æ¡ng dáº¡ng ná»‘t/khá»‘i. Cáº§n Ä‘Ã¡nh giÃ¡ thÃªm báº±ng CT ngá»±c Ä‘á»ƒ xÃ¡c Ä‘á»‹nh tÃ­nh cháº¥t vÃ  theo dÃµi diá»…n tiáº¿n."
            else:
                return "KhÃ´ng phÃ¡t hiá»‡n tá»•n thÆ°Æ¡ng dáº¡ng ná»‘t hay khá»‘i rÃµ trÃªn áº£nh X-quang nÃ y."
        
        else:
            return "ÄÃ¢y lÃ  káº¿t quáº£ phÃ¢n tÃ­ch sÆ¡ bá»™ cá»§a AI. Vui lÃ²ng Ä‘áº·t cÃ¢u há»i cá»¥ thá»ƒ hÆ¡n Ä‘á»ƒ Ä‘Æ°á»£c há»— trá»£ chi tiáº¿t, hoáº·c tham kháº£o Ã½ kiáº¿n bÃ¡c sÄ© chuyÃªn khoa."
    
    def chat(
        self,
        messages: List[dict],
        image: Optional[Image.Image] = None,
        max_new_tokens: int = 512,
    ) -> Tuple[str, int]:
        """Mock multi-turn chat.
        
        Args:
            messages: List of chat messages
            image: Optional image context
            max_new_tokens: Ignored in mock
            
        Returns:
            Tuple of (response text, tokens used (simulated))
        """
        # Simulate delay
        time.sleep(random.uniform(0.1, 0.3))
        
        # Get last user message
        last_message = ""
        for msg in reversed(messages):
            if msg.get("role") == "user":
                last_message = msg.get("content", "")
                break
        
        # Check if message contains AI detection results (from ai_service)
        has_detections = "CÃ¡c phÃ¡t hiá»‡n tá»« AI:" in last_message
        
        # Generate contextual response based on whether detections were found
        if has_detections:
            # Parse detection info from message
            response = self._generate_detection_based_response(last_message)
        else:
            response = self._generate_question_response(last_message, [])
        
        if not response or response == "":
            response = """Cáº£m Æ¡n báº¡n Ä‘Ã£ sá»­ dá»¥ng trá»£ lÃ½ AI phÃ¢n tÃ­ch X-quang.

TÃ´i cÃ³ thá»ƒ há»— trá»£:
- PhÃ¢n tÃ­ch áº£nh X-quang ngá»±c
- Giáº£i thÃ­ch cÃ¡c phÃ¡t hiá»‡n báº¥t thÆ°á»ng
- Tráº£ lá»i cÃ¢u há»i vá» hÃ¬nh áº£nh

Vui lÃ²ng upload áº£nh X-quang vÃ  Ä‘áº·t cÃ¢u há»i cá»¥ thá»ƒ Ä‘á»ƒ Ä‘Æ°á»£c há»— trá»£ tá»‘t nháº¥t.

*LÆ°u Ã½: ÄÃ¢y lÃ  há»‡ thá»‘ng AI há»— trá»£, káº¿t quáº£ cáº§n Ä‘Æ°á»£c bÃ¡c sÄ© xÃ¡c nháº­n.*"""
        
        # Simulate token count
        tokens_used = len(response) // 4 + random.randint(10, 50)
        
        return response, tokens_used
    
    def _generate_detection_based_response(self, message: str) -> str:
        """Generate response when AI detections are present in message."""
        # Extract the actual question (after the detection list)
        parts = message.split("\n\n", 1)
        question = parts[-1] if len(parts) > 1 else message
        
        # Check what was detected
        message_lower = message.lower()
        
        # Build response based on detected classes
        findings = []
        
        # Check for various conditions in the detection text
        # VinDR-CXR 14 classes + other common findings
        detection_mappings = {
            # VinDR-CXR Classes (14 classes from best.pt)
            "aortic enlargement": "PhÃ¬nh Ä‘á»™ng máº¡ch chá»§ (Aortic enlargement) - cáº§n siÃªu Ã¢m tim Ä‘Ã¡nh giÃ¡",
            "atelectasis": "Xáº¹p phá»•i (Atelectasis) - giáº£m thá»ƒ tÃ­ch phá»•i",
            "calcification": "VÃ´i hÃ³a (Calcification) - cÃ³ thá»ƒ lÃ  tá»•n thÆ°Æ¡ng cÅ© Ä‘Ã£ lÃ nh",
            "cardiomegaly": "Tim to (Cardiomegaly) - chá»‰ sá»‘ tim/ngá»±c cÃ³ thá»ƒ > 50%",
            "consolidation": "ÄÃ´ng Ä‘áº·c phá»•i (Consolidation) - vÃ¹ng má» Ä‘á»“ng nháº¥t trong nhu mÃ´",
            "ild": "Bá»‡nh phá»•i káº½ (ILD) - cáº§n HRCT Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ chi tiáº¿t",
            "infiltration": "ThÃ¢m nhiá»…m phá»•i (Infiltration) - vÃ¹ng má» khÃ´ng Ä‘á»“ng nháº¥t",
            "lung opacity": "VÃ¹ng má» phá»•i (Lung Opacity) - cáº§n Ä‘á»‘i chiáº¿u lÃ¢m sÃ ng",
            "nodule/mass": "Ná»‘t/Khá»‘i u phá»•i (Nodule/Mass) - cáº§n CT Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ chi tiáº¿t",
            "nodule": "Ná»‘t phá»•i - cáº§n theo dÃµi vÃ  Ä‘Ã¡nh giÃ¡ thÃªm",
            "mass": "Khá»‘i u phá»•i - cáº§n CT Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ chi tiáº¿t",
            "pleural effusion": "TrÃ n dá»‹ch mÃ ng phá»•i (Pleural effusion) - má» gÃ³c sÆ°á»n hoÃ nh",
            "pleural thickening": "DÃ y mÃ ng phá»•i (Pleural thickening) - cÃ³ thá»ƒ do viÃªm hoáº·c u",
            "pneumothorax": "TrÃ n khÃ­ mÃ ng phá»•i (Pneumothorax) - cáº§n can thiá»‡p náº¿u lÆ°á»£ng nhiá»u",
            "pulmonary fibrosis": "XÆ¡ phá»•i (Pulmonary fibrosis) - tá»•n thÆ°Æ¡ng xÆ¡ hÃ³a máº¡n tÃ­nh",
            "fibrosis": "XÆ¡ phá»•i - tá»•n thÆ°Æ¡ng xÆ¡ hÃ³a máº¡n tÃ­nh",
            # Additional classes
            "enlarged pa": "Äá»™ng máº¡ch phá»•i giÃ£n (Enlarged PA) - cÃ³ thá»ƒ liÃªn quan tÄƒng Ã¡p phá»•i",
            "edema": "PhÃ¹ phá»•i (Edema) - cÃ³ thá»ƒ do suy tim hoáº·c nguyÃªn nhÃ¢n khÃ¡c",
            "emphysema": "KhÃ­ pháº¿ thÅ©ng (Emphysema) - phá»•i cÄƒng giÃ£n",
            "other lesion": "Tá»•n thÆ°Æ¡ng khÃ¡c (Other lesion) - cáº§n Ä‘Ã¡nh giÃ¡ thÃªm",
        }
        
        for key, description in detection_mappings.items():
            if key in message_lower:
                findings.append(description)
        
        # If we found known findings
        if findings:
            response = f"""**Káº¿t quáº£ phÃ¢n tÃ­ch áº£nh X-quang:**

ğŸ” **CÃ¡c phÃ¡t hiá»‡n báº¥t thÆ°á»ng:**
"""
            for i, finding in enumerate(findings, 1):
                response += f"  {i}. {finding}\n"
            
            response += """
ğŸ’¡ **Äá» xuáº¥t:**
- Äá»‘i chiáº¿u vá»›i triá»‡u chá»©ng lÃ¢m sÃ ng cá»§a bá»‡nh nhÃ¢n
- CÃ³ thá»ƒ cáº§n thÃªm cÃ¡c xÃ©t nghiá»‡m bá»• sung (CT, siÃªu Ã¢m, xÃ©t nghiá»‡m mÃ¡u)
- Theo dÃµi diá»…n tiáº¿n náº¿u cáº§n thiáº¿t

âš ï¸ *ÄÃ¢y lÃ  káº¿t quáº£ phÃ¢n tÃ­ch AI há»— trá»£. Quyáº¿t Ä‘á»‹nh cuá»‘i cÃ¹ng thuá»™c vá» bÃ¡c sÄ©.*
"""
        else:
            # Unknown class detected (like class_61 from pretrained model)
            response = """**Káº¿t quáº£ phÃ¢n tÃ­ch áº£nh X-quang:**

ğŸ“‹ **Nháº­n xÃ©t:**
Há»‡ thá»‘ng AI Ä‘Ã£ phÃ¡t hiá»‡n má»™t sá»‘ vÃ¹ng cáº§n chÃº Ã½ trÃªn áº£nh X-quang. Tuy nhiÃªn, do model hiá»‡n táº¡i chÆ°a Ä‘Æ°á»£c fine-tune Ä‘áº§y Ä‘á»§ trÃªn dataset y khoa, káº¿t quáº£ cáº§n Ä‘Æ°á»£c bÃ¡c sÄ© chuyÃªn khoa xÃ¡c nháº­n.

ğŸ’¡ **Äá» xuáº¥t:**
- Cáº§n Ä‘Ã¡nh giÃ¡ thÃªm bá»Ÿi bÃ¡c sÄ© cháº©n Ä‘oÃ¡n hÃ¬nh áº£nh
- Äá»‘i chiáº¿u vá»›i triá»‡u chá»©ng lÃ¢m sÃ ng
- CÃ³ thá»ƒ cáº§n cÃ¡c xÃ©t nghiá»‡m bá»• sung

âš ï¸ *LÆ°u Ã½: Model YOLO hiá»‡n táº¡i cÃ³ thá»ƒ chÆ°a Ä‘Æ°á»£c train trÃªn VinDR-CXR. Vui lÃ²ng kiá»ƒm tra file weights/yolo/best.pt*
"""
        
        return response


# Singleton instance
_mock_qwen_service: Optional[MockQwenVLService] = None


def get_mock_qwen_service() -> MockQwenVLService:
    """Get or create mock Qwen-VL service singleton."""
    global _mock_qwen_service
    if _mock_qwen_service is None:
        _mock_qwen_service = MockQwenVLService()
    return _mock_qwen_service
